{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3770b2cc5ca97dcdd18d19ac6dc65f1",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 4: Data Privacy\n",
    "\n",
    "This assignment covers getting data (web scraping) and data privacy (Safe Harbor). \n",
    "\n",
    "This assignment is out of 7.5 points, worth 7.5% of your grade.\n",
    "\n",
    "**PLEASE DO NOT CHANGE THE NAME OF THIS FILE.**\n",
    "\n",
    "**PLEASE DO NOT COPY & PASTE OR DELETE CELLS INLCUDED IN THE ASSIGNMENT.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6254721ba8721d30a815a6a7bf0608f8",
     "grade": false,
     "grade_id": "important",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Important Reminders\n",
    "\n",
    "- Do not change / update / delete any existing cells with 'assert' in them. These are the tests used to check your assignment. \n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted file. Passing all the tests you can see in the notebook here does not guarantee you have the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "020b280f2bd1564f1829f62d8b3a4853",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We have briefly discussed in lecture the importance and the mechanics of protecting individuals' privacy when they are included in datasets. \n",
    "\n",
    "One method to do so is the Safe Harbor Method. The Safe Harbor method specifies how to protect individuals' identities by telling us which information to remove from a dataset in order to avoid accidently disclosing personal information. \n",
    "\n",
    "In this assignment, we will explore web scraping, which can often include personally identifiable information, how identity can be decoded from badly anonymized datasets, and also explore using Safe Harbor to anonymize datasets properly. \n",
    "\n",
    "The topics covered in this assignment are mainly covered in the 'DataGathering' and 'DataPrivacy&Anonymization' Tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eea06ff714fd3f00b5474b36d522ca50",
     "grade": false,
     "grade_id": "import-code",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these are provided for you. Do not import any other packages.\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e880f9e98ce6934ecd598b43912cbbec",
     "grade": false,
     "grade_id": "cell-25153cbdcaad4068",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Web Scraping (1.25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0849ef8eb699ba087d8dd81e4a604c87",
     "grade": false,
     "grade_id": "cell-76ae256b5f7132b6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Scraping Rules\n",
    "\n",
    "1) If you are using another organization's website for scraping, make sure to check the website's terms & conditions. \n",
    "\n",
    "2) Do not request data from the website too aggressively (quickly) with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "\n",
    "3) The layout of a website may change from time to time. Because of this, if you're scraping a website, make sure to revisit the site and rewrite your code as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a61b0df54de2e543e781b47265bc3d48",
     "grade": false,
     "grade_id": "cell-ead298f239fc9639",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1a) Web Scrape\n",
    "\n",
    "We will first retrieve the contents on a page and examine them a bit.\n",
    "\n",
    "Make a variable called `wiki`, that stores the following URL (as a string):\n",
    "https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population\n",
    "\n",
    "Now, to open the URL, use `requests.get()` and provide `wiki` as its input. Store this in a variable called `page`.\n",
    "\n",
    "After that, make a variable called `soup` to parse the HTML using `BeautifulSoup`. Consider that there will be a method from `BeautifulSoup` that you'll need to call on to get the content from the page. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe48a65e1994c442ef55c68a34b7fe5c",
     "grade": false,
     "grade_id": "cell-889693bf71daf7c8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = \"https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population\"\n",
    "page = requests.get(wiki)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "463ec7d4dd95783b5682dbf4eda0c0cf",
     "grade": true,
     "grade_id": "cell-52fad88c14b5f276",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert wiki\n",
    "assert page\n",
    "assert soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0616421d074389b66733998b7dad69ed",
     "grade": false,
     "grade_id": "cell-0f25bbcd2e8993d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1b) Checking Scrape Contents\n",
    "\n",
    "Extract the title from the page and save it in a variable called `title_page`. \n",
    "\n",
    "Make sure you extract it as a string.\n",
    "\n",
    "To do so, you have to use the soup object created in the above cell. \n",
    "Hint: from your soup variable, you can access this with `.title.string`.\n",
    "\n",
    "Make sure you print out and check the contents of `title_page`.\n",
    "\n",
    "Note that it should not have any tags (such as `<title>` included in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a97138aa94aebed614102ca14d6c144d",
     "grade": false,
     "grade_id": "cell-4d0a0b26ed667fe0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of states and territories of the United States by population - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "title_page = soup.title.string\n",
    "print(title_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f18f1426ae8f7e546c87095d78b5b8c",
     "grade": true,
     "grade_id": "cell-25e2c00e1488f142",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert title_page\n",
    "assert isinstance(title_page, str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a338eb0678a54944847a9fd5b5ec0275",
     "grade": false,
     "grade_id": "cell-a64ca12576cb4bd8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1c) Extracting Tables\n",
    "\n",
    "In order to extract the data we want, we'll start with extracting a data table of interest.\n",
    "\n",
    "Note that you can see this table by going to look at the link we scraped.\n",
    "\n",
    "Use the `soup` object and call a method called `find`, which will find and extract the first table in the scraped webpage. Store this in the variable `right_table`. \n",
    "\n",
    "Note: you need to search for the name `table`, and set the `class_` argument as `wikitable sortable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddf8cc5d3ff6c8d6c08d42c320edf670",
     "grade": false,
     "grade_id": "cell-8da7172c1da665fe",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "right_table = soup.find(\"table\", class_ = \"wikitable sortable\" )\n",
    "\n",
    "#ask ta if it's supposed to be \"class_\"or just class. cause nothing happens with class_ variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba5414a74acd285a248c99cd4a373712",
     "grade": true,
     "grade_id": "cell-6a079fac89c3332c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert right_table\n",
    "assert isinstance(right_table, bs4.element.Tag)\n",
    "assert right_table.name == 'table'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7209248c98dd2998e7a1d56e14528c5e",
     "grade": false,
     "grade_id": "cell-702d9d7fe1f16d2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now, you'll extract the data from the table into lists.\n",
    "\n",
    "Note: This code is provided for you. Do read through it and try to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff808ef7cb40e46b037fb7e0b8ddd950",
     "grade": false,
     "grade_id": "cell-6219dfad1bd6ba7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE PROVIDED\n",
    "# YOU SHOULD NOT HAVE TO EDIT\n",
    "# BUT YOU WILL WANT TO UNDERSTAND\n",
    "list_a, list_b, list_c = [], [], []\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "    \n",
    "    cells = row.findAll('td')\n",
    "    \n",
    "    # Skips rows that aren't 10 columns long (like the heading)\n",
    "    if len(cells) != 12:\n",
    "        continue\n",
    "\n",
    "    # This catches when the name cells stops having a link\n",
    "    #  and ends, skipping the last (summary rows)\n",
    "    try:\n",
    "        list_a.append(cells[2].find('a').text)\n",
    "        list_b.append(cells[3].find(text=True))\n",
    "        list_c.append(cells[4].find(text=True))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "276e728f170dbc817864de61877d2130",
     "grade": false,
     "grade_id": "cell-664bad5a4103cf19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1d) Collecting into a dataframe\n",
    "\n",
    "Create a dataframe `my_df` and add the data from the lists above to it. \n",
    "- `list_a` is the state or territory name. Set the column name as `State`, and make this the index\n",
    "- `list_b` is the population estimate. Add it to the dataframe, and set the column name as `Population Estimate`\n",
    "- `list_c` is the census population. Add it to the dataframe, and set the column name as `Census Population`\n",
    "\n",
    "make sure to check the head of your dataframe to see that everything looks right! ie: my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5063c4bddc2054828c0469b58bc52635",
     "grade": false,
     "grade_id": "cell-3b72a498799ef251",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population Estimate</th>\n",
       "      <th>Census Population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>39,512,223\\n</td>\n",
       "      <td>37,254,523\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>28,995,881\\n</td>\n",
       "      <td>25,145,561\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>21,477,737\\n</td>\n",
       "      <td>18,801,310\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>19,453,561\\n</td>\n",
       "      <td>19,378,102\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>12,801,989\\n</td>\n",
       "      <td>12,702,379\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>12,671,821\\n</td>\n",
       "      <td>12,830,632\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>11,689,100\\n</td>\n",
       "      <td>11,536,504\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>10,617,423\\n</td>\n",
       "      <td>9,687,653\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>10,488,084\\n</td>\n",
       "      <td>9,535,483\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>9,986,857\\n</td>\n",
       "      <td>9,883,640\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>8,882,190\\n</td>\n",
       "      <td>8,791,894\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>8,535,519\\n</td>\n",
       "      <td>8,001,024\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>7,614,893\\n</td>\n",
       "      <td>6,724,540\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>7,278,717\\n</td>\n",
       "      <td>6,392,017\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>6,949,503\\n</td>\n",
       "      <td>6,547,629\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>6,833,174\\n</td>\n",
       "      <td>6,346,105\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>6,732,219\\n</td>\n",
       "      <td>6,483,802\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>6,137,428\\n</td>\n",
       "      <td>5,988,927\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>6,045,680\\n</td>\n",
       "      <td>5,773,552\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>5,822,434\\n</td>\n",
       "      <td>5,686,986\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>5,758,736\\n</td>\n",
       "      <td>5,029,196\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>5,639,632\\n</td>\n",
       "      <td>5,303,925\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>5,148,714\\n</td>\n",
       "      <td>4,625,364\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>4,903,185\\n</td>\n",
       "      <td>4,779,736\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>4,648,794\\n</td>\n",
       "      <td>4,533,372\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>4,467,673\\n</td>\n",
       "      <td>4,339,367\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>4,217,737\\n</td>\n",
       "      <td>3,831,074\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>3,956,971\\n</td>\n",
       "      <td>3,751,351\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>3,565,287\\n</td>\n",
       "      <td>3,574,097\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>3,205,958\\n</td>\n",
       "      <td>2,763,885\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>3,155,070\\n</td>\n",
       "      <td>3,046,355\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>3,193,694\\n</td>\n",
       "      <td>3,725,789\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>3,080,156\\n</td>\n",
       "      <td>2,700,551\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>3,017,825\\n</td>\n",
       "      <td>2,915,918\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>2,976,149\\n</td>\n",
       "      <td>2,967,297\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>2,913,314\\n</td>\n",
       "      <td>2,853,118\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>2,096,829\\n</td>\n",
       "      <td>2,059,179\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>1,934,408\\n</td>\n",
       "      <td>1,826,341\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>1,787,065\\n</td>\n",
       "      <td>1,567,582\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>1,792,147\\n</td>\n",
       "      <td>1,852,994\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>1,415,872\\n</td>\n",
       "      <td>1,360,301\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>1,359,711\\n</td>\n",
       "      <td>1,316,470\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>1,344,212\\n</td>\n",
       "      <td>1,328,361\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>1,068,778\\n</td>\n",
       "      <td>989,415\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>1,059,361\\n</td>\n",
       "      <td>1,052,567\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>973,764\\n</td>\n",
       "      <td>897,934\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>884,659\\n</td>\n",
       "      <td>814,180\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>762,062\\n</td>\n",
       "      <td>672,591\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>731,545\\n</td>\n",
       "      <td>710,231\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>705,749\\n</td>\n",
       "      <td>601,723\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>623,989\\n</td>\n",
       "      <td>625,741\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>578,759\\n</td>\n",
       "      <td>563,626\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guam</th>\n",
       "      <td>165,718\\n</td>\n",
       "      <td>159,358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Virgin Islands</th>\n",
       "      <td>104,914\\n</td>\n",
       "      <td>106,405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>55,641\\n</td>\n",
       "      <td>55,519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern Mariana Islands</th>\n",
       "      <td>55,194\\n</td>\n",
       "      <td>53,883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contiguous United States</th>\n",
       "      <td>325,386,357\\n</td>\n",
       "      <td>306,675,006\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Population Estimate Census Population\n",
       "State                                                         \n",
       "California                      39,512,223\\n      37,254,523\\n\n",
       "Texas                           28,995,881\\n      25,145,561\\n\n",
       "Florida                         21,477,737\\n      18,801,310\\n\n",
       "New York                        19,453,561\\n      19,378,102\\n\n",
       "Pennsylvania                    12,801,989\\n      12,702,379\\n\n",
       "Illinois                        12,671,821\\n      12,830,632\\n\n",
       "Ohio                            11,689,100\\n      11,536,504\\n\n",
       "Georgia                         10,617,423\\n       9,687,653\\n\n",
       "North Carolina                  10,488,084\\n       9,535,483\\n\n",
       "Michigan                         9,986,857\\n       9,883,640\\n\n",
       "New Jersey                       8,882,190\\n       8,791,894\\n\n",
       "Virginia                         8,535,519\\n       8,001,024\\n\n",
       "Washington                       7,614,893\\n       6,724,540\\n\n",
       "Arizona                          7,278,717\\n       6,392,017\\n\n",
       "Massachusetts                    6,949,503\\n       6,547,629\\n\n",
       "Tennessee                        6,833,174\\n       6,346,105\\n\n",
       "Indiana                          6,732,219\\n       6,483,802\\n\n",
       "Missouri                         6,137,428\\n       5,988,927\\n\n",
       "Maryland                         6,045,680\\n       5,773,552\\n\n",
       "Wisconsin                        5,822,434\\n       5,686,986\\n\n",
       "Colorado                         5,758,736\\n       5,029,196\\n\n",
       "Minnesota                        5,639,632\\n       5,303,925\\n\n",
       "South Carolina                   5,148,714\\n       4,625,364\\n\n",
       "Alabama                          4,903,185\\n       4,779,736\\n\n",
       "Louisiana                        4,648,794\\n       4,533,372\\n\n",
       "Kentucky                         4,467,673\\n       4,339,367\\n\n",
       "Oregon                           4,217,737\\n       3,831,074\\n\n",
       "Oklahoma                         3,956,971\\n       3,751,351\\n\n",
       "Connecticut                      3,565,287\\n       3,574,097\\n\n",
       "Utah                             3,205,958\\n       2,763,885\\n\n",
       "Iowa                             3,155,070\\n       3,046,355\\n\n",
       "Puerto Rico                      3,193,694\\n       3,725,789\\n\n",
       "Nevada                           3,080,156\\n       2,700,551\\n\n",
       "Arkansas                         3,017,825\\n       2,915,918\\n\n",
       "Mississippi                      2,976,149\\n       2,967,297\\n\n",
       "Kansas                           2,913,314\\n       2,853,118\\n\n",
       "New Mexico                       2,096,829\\n       2,059,179\\n\n",
       "Nebraska                         1,934,408\\n       1,826,341\\n\n",
       "Idaho                            1,787,065\\n       1,567,582\\n\n",
       "West Virginia                    1,792,147\\n       1,852,994\\n\n",
       "Hawaii                           1,415,872\\n       1,360,301\\n\n",
       "New Hampshire                    1,359,711\\n       1,316,470\\n\n",
       "Maine                            1,344,212\\n       1,328,361\\n\n",
       "Montana                          1,068,778\\n         989,415\\n\n",
       "Rhode Island                     1,059,361\\n       1,052,567\\n\n",
       "Delaware                           973,764\\n         897,934\\n\n",
       "South Dakota                       884,659\\n         814,180\\n\n",
       "North Dakota                       762,062\\n         672,591\\n\n",
       "Alaska                             731,545\\n         710,231\\n\n",
       "District of Columbia               705,749\\n         601,723\\n\n",
       "Vermont                            623,989\\n         625,741\\n\n",
       "Wyoming                            578,759\\n         563,626\\n\n",
       "Guam                               165,718\\n           159,358\n",
       "U.S. Virgin Islands                104,914\\n           106,405\n",
       "American Samoa                      55,641\\n            55,519\n",
       "Northern Mariana Islands            55,194\\n            53,883\n",
       "Contiguous United States       325,386,357\\n     306,675,006\\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = {'State': list_a, 'Population Estimate': list_b, \"Census Population\": list_c}\n",
    "my_df = pd.DataFrame(data=my_df).set_index(\"State\")\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c96e59e97bd94afd281f90ac19d180",
     "grade": true,
     "grade_id": "cell-406fc7a4b3d93852",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance (my_df, pd.DataFrame)\n",
    "assert my_df.index.name == 'State'\n",
    "assert list(my_df.columns) == ['Population Estimate', 'Census Population']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7fc34eab0671d014a5eafd8c2659c5d",
     "grade": false,
     "grade_id": "cell-e1e19e886aca2b94",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1e) Using the data\n",
    "What is the Population Estimate of Texas? Save this answer to a variable called `texas_pop`\n",
    "Notes:\n",
    "- Extract this value programmatically from your dataframe (as in, don't set it explicitly as `texas_pop = 123`)\n",
    "- You can use `.loc` to extract a particular value from a dataframe.\n",
    "- The data in your dataframe will be strings - that's fine, leave them as strings (don't typecast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909b67461592f43d9debcf088b5c9762",
     "grade": false,
     "grade_id": "cell-552f1cceb6530fef",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "texas_pop = my_df.loc['Texas', 'Population Estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5178f2c0080e546d66ebd86a95630dba",
     "grade": true,
     "grade_id": "cell-00910bf76609b48e",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert texas_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f337e0e61199cd4f3f5726bc5cf5ad1f",
     "grade": false,
     "grade_id": "p1-title",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Identifying Data (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfebd3a04afa674d607ee42e853ec4dd",
     "grade": false,
     "grade_id": "p1-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Data Files:\n",
    "- anon_user_dat.json\n",
    "- employee_info.json\n",
    "\n",
    "You will first be working with a file called 'anon_user_dat.json'. This file contains information about some (fake) Tinder users. When creating an account, each Tinder user was asked to provide their first name, last name, work email (to verify the disclosed workplace), age, gender, phone # and zip code. Before releasing this data, a data scientist cleaned the data to protect the privacy of Tinder's users by removing the obvious personal identifiers: phone #, zip code, and IP address. However, the data scientist chose to keep each users' email addresses because when they visually skimmed a couple of the email addresses none of them seemed to have any of the users' actual names in them. This is where the data scientist made a huge mistake!\n",
    "\n",
    "We will take advantage of having the work email addresses by finding the employee information of different companies and matching that employee information with the information we have, in order to identify the names of the secret Tinder users!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c801ec141b760a1eafe44fc82f67f20c",
     "grade": false,
     "grade_id": "cell-9c07a2e1f6bf36f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2a) Load in the 'cleaned' data \n",
    "\n",
    "Load the `anon_user_dat.json` json file into a pandas dataframe. Call it `df_personal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2058dbc61296d005826083c5972632e2",
     "grade": false,
     "grade_id": "1a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_personal = pd.read_json(\"anon_user_dat.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d36df293540acb7600d888e2124392a9",
     "grade": true,
     "grade_id": "1a-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_personal, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80977f02cc275a5ec38e285bea8503ac",
     "grade": false,
     "grade_id": "cell-0e20f9f530c04e91",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2b) Check the first 10 emails \n",
    "\n",
    "Save the first 10 emails to a Series, and call it `sample_emails`. \n",
    "You should then print out this Series. ( Use print() )\n",
    "\n",
    "The purpose of this is to get a sense of how these work emails are structured and how we could possibly extract where each anonymous user seems to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14b9deef20a33a2c2f2fbdfc51baefc5",
     "grade": false,
     "grade_id": "1b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "sample_emails = df_personal['email'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c424c0f41f2b77ce520ddd10c1f74a1a",
     "grade": true,
     "grade_id": "1b-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(sample_emails, pd.Series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a195255da57b3d547a63784183e55920",
     "grade": false,
     "grade_id": "cell-7e5e9f0cf8fc03f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2c) Extract the Company Name From the Email \n",
    "\n",
    "Create a function with the following specifications:\n",
    "- Function Name: extract_company\n",
    "- Purpose: to extract the company of the email (i.e., everything after the @ sign but before the .)\n",
    "- Parameter(s): email (string)\n",
    "- Returns: The extracted part of the email (string)\n",
    "- Hint: This should take 1 line of code. Look into the find('') method. \n",
    "\n",
    "You can start with this outline:\n",
    "```python \n",
    "def extract_company(email):\n",
    "    return\n",
    "```\n",
    "\n",
    "Example Usage: \n",
    "- extract_company(\"larhe@uber.com\") should return \"uber\"\n",
    "- extract_company(“ds@cogs.edu”) should return “cogs”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0825f2f7b2c060c3fb4d62705faadfa",
     "grade": false,
     "grade_id": "1c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seattletimes'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company(email):\n",
    "    \n",
    "    start = email.find(\"@\")\n",
    "    end = email.find('.')\n",
    "    \n",
    "    return email[start+1:end]\n",
    "extract_company(\"gshoreson0@seattletimes.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c08f9d6ed4a35628a1e1dbddad80e62c",
     "grade": true,
     "grade_id": "1c-tests",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert extract_company(\"gshoreson0@seattletimes.com\") == \"seattletimes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ef7d9e3ecb79343b5b35d3aa70891a8",
     "grade": false,
     "grade_id": "info",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "With a little bit of basic sleuthing (aka googling) and web-scraping (aka selectively reading in html code) it turns out that you've been able to collect information about all the present employees/interns of the companies you are interested in. Specifically, on each company website, you have found the name, gender, and age of its employees. You have saved that info in employee_info.json and plan to see if, using this new information, you can match the Tinder accounts to actual names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "126b672f7d2ab5943234db0aaea0cd48",
     "grade": false,
     "grade_id": "cell-966cd614a1dfc14a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2d) Load in employee data \n",
    "\n",
    "Load the json file into a pandas dataframe. Call it `df_employee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7057c88392d0cea08bd2a82a292aaf6e",
     "grade": false,
     "grade_id": "1d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_employee = pd.read_json('employee_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfdeb2f667f05c9eb2d7163d66360040",
     "grade": true,
     "grade_id": "1d-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_employee, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cec0a69913e1abf34931a10fef4084fa",
     "grade": false,
     "grade_id": "cell-4559a646829c48ab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2e) Match the employee name with company, age, gender \n",
    "\n",
    "Create a function with the following specifications:\n",
    "- Function name: employee_matcher\n",
    "- Purpose: to match the employee name with the provided company, age, and gender\n",
    "- Parameter(s): company (string), age (int), gender (string)\n",
    "- Returns: The employee first_name and last_name like this: return first_name, last_name \n",
    "- Note: If there are multiple employees that fit the same description, first_name and last_name should return a list of all possible first names and last names i.e., ['Desmund', 'Kelby'], ['Shepley', 'Tichner']. Note that the names of the individuals that would produce this output are 'Desmund Shepley' and 'Kelby Tichner'.\n",
    "\n",
    "Hint:\n",
    "There are many different ways to code this. An inelegant solution is to loop through `df_employee` \n",
    "   and for each data item see if the company, age, and gender match\n",
    "   i.e., \n",
    "   ```python\n",
    "   for i in range(0, len(df_employee)):\n",
    "             if (company == df_employee.ix[i,'company']):\n",
    "   ```\n",
    "   \n",
    "However! The solution above is very inefficient and long, so you should try to look into this:\n",
    "Google the df.loc method: It extracts pieces of the dataframe\n",
    "   if it fulfills a certain condition.\n",
    "   i.e., \n",
    "   \n",
    "```python\n",
    "df_employee.loc[df_employee['company'] == company]\n",
    "```\n",
    "\n",
    "If you need to convert your pandas data series into a list, you can do ```list(result)``` where result is a pandas \"series\"\n",
    "\n",
    "You can start with this outline:\n",
    "```python\n",
    "def employee_matcher(company, age, gender):\n",
    "    return first_name, last_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5b44786fb001c854708a21d4ee09a41",
     "grade": false,
     "grade_id": "1e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Maxwell'], ['Jorio'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def employee_matcher(company, age, gender):\n",
    "    temp = df_employee.loc[(df_employee[\"company\"]== company)\n",
    "    & (df_employee['age'] == age) & (df_employee ['gender'] == gender)]\n",
    "    \n",
    "    first = temp['first_name']\n",
    "    last = temp ['last_name']\n",
    "    return list (first), list(last)\n",
    "employee_matcher(\"google\", 41, \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c65bd3cd1ecdd921ce23d383547972ee",
     "grade": true,
     "grade_id": "1e-tests",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert employee_matcher(\"google\", 41, \"Male\") == (['Maxwell'], ['Jorio'])\n",
    "assert employee_matcher(\"salon\", 47, \"Female\") == (['Elenore'], ['Gravett'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8c8043b0eccf14a73824e0bf4156a29",
     "grade": false,
     "grade_id": "cell-33434f8addc21493",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2f) Extract all the private data \n",
    "\n",
    "- Create 2 empty lists called `first_names` and `last_names`\n",
    "- Loop through all the people we are trying to identify in df_personal\n",
    "- Call the `extract_company` function (i.e., `extract_company(df_personal.ix[i, 'email'])` )\n",
    "- Call the `employee_matcher` function \n",
    "- Append the results of `employee_matcher` to the appropriate lists (`first_names` and `last_names`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6532f4528b73ef0ab65b46df04c3562",
     "grade": false,
     "grade_id": "1f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "first_names = []\n",
    "last_names = []\n",
    "\n",
    "for p in df_personal.index:\n",
    "    email = extract_company(df_personal.loc[p,'email'])\n",
    "    \n",
    "    age = df_personal.loc[p,\"age\"]\n",
    "    gender = df_personal.loc[p,\"gender\"]\n",
    "    value = employee_matcher(email,age,gender)\n",
    "    \n",
    "    first_names.append(value[0])\n",
    "    last_names.append(value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ba02cddc3cce33e7ce87888ed29743c",
     "grade": true,
     "grade_id": "1f-tests",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert first_names[45:50]== [['Justino'], ['Tadio'], ['Kennith'], ['Cedric'], ['Amargo']]\n",
    "assert last_names[45:50] == [['Corro'], ['Blackford'], ['Milton'], ['Yggo'], ['Grigor']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9323733665f99989d01ad966f74e65c1",
     "grade": false,
     "grade_id": "cell-4195840f34782b50",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2g) Add the names to the original 'secure' dataset! \n",
    "\n",
    "We have done this last step for you below, all you need to do is run this cell.\n",
    "\n",
    "For your own personal enjoyment, you should also print out the new `df_personal` with the identified people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a33a74929433dd501bfcdbc349b96a9f",
     "grade": false,
     "grade_id": "1g",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_personal['first_name'] = first_names\n",
    "df_personal['last_name'] = last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age                        email  gender           first_name  \\\n",
      "0     60  gshoreson0@seattletimes.com    Male             [Gordon]   \n",
      "1     47           eweaben1@salon.com  Female            [Elenore]   \n",
      "2     27      akillerby2@gravatar.com    Male               [Abbe]   \n",
      "3     46            gsainz3@zdnet.com    Male              [Guido]   \n",
      "4     72     bdanilewicz4@4shared.com    Male              [Brody]   \n",
      "..   ...                          ...     ...                  ...   \n",
      "995    3        pstroulgerrn@time.com  Female           [Penelopa]   \n",
      "996   49  kbasnettro@seattletimes.com  Female  [Anthiathia, Kandy]   \n",
      "997   75  pmortlockrp@liveinternet.ru    Male               [Paco]   \n",
      "998   81         sphetterq@toplist.cz    Male              [Sammy]   \n",
      "999   70        jtyresrr@slashdot.org    Male             [Josiah]   \n",
      "\n",
      "             last_name  \n",
      "0          [DelaField]  \n",
      "1            [Gravett]  \n",
      "2          [Stockdale]  \n",
      "3            [Comfort]  \n",
      "4           [Pinckard]  \n",
      "..                 ...  \n",
      "995            [Roman]  \n",
      "996  [Baldwin, Cossam]  \n",
      "997      [Weatherburn]  \n",
      "998           [Dymick]  \n",
      "999         [Ayshford]  \n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_personal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "220e03ead46597189f618c88f0088bcc",
     "grade": false,
     "grade_id": "wrap-p1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We have now just discovered the 'anonymous' identities of all the registered Tinder users...awkward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb76c8b1a9e9f29da9e9edacaf2a738c",
     "grade": false,
     "grade_id": "p2-title",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Anonymize Data (3.25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28f7733eb649c467c1e05df6a0287439",
     "grade": false,
     "grade_id": "p2-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You are hopefully now convinced that with some seemingly harmless data a hacker can pretty easily discover the identities of certain users. Thus, we will now clean the original Tinder data ourselves according to the Safe Harbor Method in order to make sure that it has been *properly* cleaned..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "297011bf54f76dc4adbdecdbfc30cf2b",
     "grade": false,
     "grade_id": "cell-e1e38873a48800d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3a) Load in personal data \n",
    "\n",
    "Load the `user_dat.csv` file into a pandas dataframe. Call it `df_users`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "993d36cc155397bbe43169ba1abd34be",
     "grade": false,
     "grade_id": "2a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>phone</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>clilleymanlm@irs.gov</td>\n",
       "      <td>Carly</td>\n",
       "      <td>Female</td>\n",
       "      <td>Duckels</td>\n",
       "      <td>229.46.197.198</td>\n",
       "      <td>(445)515-0719</td>\n",
       "      <td>70397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>parnecke9a@furl.net</td>\n",
       "      <td>Prisca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Friec</td>\n",
       "      <td>60.255.20.98</td>\n",
       "      <td>(962)747-5149</td>\n",
       "      <td>71965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>ldankersley7j@mysql.com</td>\n",
       "      <td>Lauree</td>\n",
       "      <td>Female</td>\n",
       "      <td>Meineking</td>\n",
       "      <td>65.148.56.18</td>\n",
       "      <td>(221)690-1264</td>\n",
       "      <td>47946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>kcattrollma@msn.com</td>\n",
       "      <td>Karoly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hoyles</td>\n",
       "      <td>207.40.101.214</td>\n",
       "      <td>(203)282-1167</td>\n",
       "      <td>29063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>rchestney60@dailymotion.com</td>\n",
       "      <td>Rona</td>\n",
       "      <td>Female</td>\n",
       "      <td>St. Quentin</td>\n",
       "      <td>177.12.128.156</td>\n",
       "      <td>(703)482-9159</td>\n",
       "      <td>68872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                        email first_name  gender    last_name  \\\n",
       "0   34         clilleymanlm@irs.gov      Carly  Female      Duckels   \n",
       "1   87          parnecke9a@furl.net     Prisca     NaN     Le Friec   \n",
       "2   60      ldankersley7j@mysql.com     Lauree  Female    Meineking   \n",
       "3   47          kcattrollma@msn.com     Karoly     NaN       Hoyles   \n",
       "4   85  rchestney60@dailymotion.com       Rona  Female  St. Quentin   \n",
       "\n",
       "       ip_address          phone    zip  \n",
       "0  229.46.197.198  (445)515-0719  70397  \n",
       "1    60.255.20.98  (962)747-5149  71965  \n",
       "2    65.148.56.18  (221)690-1264  47946  \n",
       "3  207.40.101.214  (203)282-1167  29063  \n",
       "4  177.12.128.156  (703)482-9159  68872  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = pd.read_csv(\"user_dat.csv\")\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "899435eddf4c4d16f99baaf4070b5635",
     "grade": true,
     "grade_id": "2a-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_users, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "433456d85e5131b23caabfd51a6b59ca",
     "grade": false,
     "grade_id": "cell-6de4847fa7cf9858",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3b) Drop personal attributes \n",
    "\n",
    "Remove any personal information, following the Safe Harbor method.\n",
    "Based on the Safe Harbor method, remove any columns from `df_users` that contain personal information. \n",
    "\n",
    "Note that details on the Safe Harbor method are covered in the Tutorials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acd38c5a94a8855fe473d2c4ebf3c564",
     "grade": false,
     "grade_id": "2b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop([\"first_name\", \"last_name\", \"email\", \"phone\", \"ip_address\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc4cd7c6dff9718afc4dd96345145680",
     "grade": true,
     "grade_id": "2b-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users.columns) == 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adecbf8ea4ec18a861d2bacb490496a4",
     "grade": false,
     "grade_id": "cell-cde4461bea3e36e6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3c) Drop ages that are above 90 \n",
    "\n",
    "Safe Harbor rule C: Drop all the rows which have age greater than 90 from `df_users`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3328d6bd76aa6996b76b96f8b447e3ec",
     "grade": false,
     "grade_id": "2c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans = df_users[df_users[\"age\"] > 90].index\n",
    "\n",
    "df_users.drop(ans, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b519a85a8f2b78d2d757cbe2fed03b8",
     "grade": true,
     "grade_id": "2c-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_users.shape == (943, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7cc1100f227a29d4ab0620e664ce497",
     "grade": false,
     "grade_id": "cell-6e3e8c23e95148aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3d) Load in zip code data \n",
    "\n",
    "Load the zip_pop.csv file into a (different) pandas dataframe. Call it `df_zip`.\n",
    "\n",
    "Note that the zip data should be read in as strings, not ints, as would be the default. \n",
    "\n",
    "In `read_csv`, use the parameter `dtype` to specify to read `zip` as str, and `population` as int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3186b1d7c166625bf53f3259161a30a",
     "grade": false,
     "grade_id": "2d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_zip = pd.read_csv('zip_pop.csv' , dtype = {\"zip\":str, \"population\":int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15756195b928bbd155eb88ef3ff8ff53",
     "grade": true,
     "grade_id": "2d-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_zip, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f697ab5b8c59c3af2c02a00816b1103",
     "grade": false,
     "grade_id": "cell-cdf6b3de6c2f461d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3e) Sort zipcodes into \"Geographic Subdivision\" \n",
    "\n",
    "The Safe Harbor Method applies to \"Geographic Subdivisions\" as opposed to each zipcode itself. \n",
    "\n",
    "Geographic Subdivision: All areas which share the first 3 digits of a zip code\n",
    "\n",
    "Count the total population for each geographic subdivision, storing the first 3 digits of the zip code and its corresponding population in the dictionary `zip_dict`. (For example, if there were 20 people whose zip code started with 090, the key-value pair in `zip_dict` would be `{'090' : 20}`.)\n",
    "\n",
    "You may be tempted to write a gnarly loop to accomplish this. Avoid that temptation. Instead, you'll want to be savy with a dictionary and `groupby` from `pandas` here. \n",
    "\n",
    "To get you started...\n",
    "\n",
    "If you wanted to group by whole zip code, you could use something like this:\n",
    "\n",
    "```python\n",
    "df_zip.groupby(df_zip['zip'])\n",
    "```\n",
    "\n",
    "But, we don't want to group by the *entire* zip code. Instead, we want to extract the first 3 digits of a zip code, and group by that. \n",
    "\n",
    "To extract the first three digits, you could so something like the following:\n",
    "\n",
    "```python\n",
    "df_zip['zip'].str[:3]\n",
    "```\n",
    "\n",
    "You'll want to combine these two concepts, such that you store this information in a dictionary `zip_dict`, which stores the first three digits of the zip code as the key and the population of that 3-digit zip code as the value.\n",
    "\n",
    "(If you're stuck and/or to better understand how dictionaries work and how they apply to this concept, check the section materials, use google, and go to discussion sections!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f2b53afb81fe1626e5db93a265380c6",
     "grade": false,
     "grade_id": "2e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "zip_dict = dict(df_zip.groupby(df_zip['zip'].str[:3])['population'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2373d9d200d3d28358b3484fcd90964e",
     "grade": true,
     "grade_id": "2e-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(zip_dict, dict)\n",
    "assert zip_dict['100'] == 1502501\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0a48aa204272d32c108782c8081c120",
     "grade": false,
     "grade_id": "cell-62f714bddd425bad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3f) Masking the Zip Codes \n",
    "\n",
    "In this part, you should write a for loop, updating the `df_users` dataframe.\n",
    "\n",
    "Go through each user, and update their zip code, to Safe Harbor specifications:\n",
    "\n",
    "- If the user is from a zip code for the which the \"Geographic Subdivision\" is less than equal to 20,000, change the zip code to 0 \n",
    "- Otherwise, change the zip code to be only the first 3 numbers of the full zip code\n",
    "- Do all this rewritting the zip_code columns of the `df_users` DataFrame\n",
    "\n",
    "Hints: \n",
    "1. This will be several lines of code, looping through the DataFrame, getting each zip code, checking the geographic subdivision with the population in `zip_dict`, and setting the `zip_code` accordingly. \n",
    "2. Be very aware of your variable types when working with zip codes here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9cc80c9f2b2c0c93b048ab904b57dbe",
     "grade": false,
     "grade_id": "2g",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_users.loc[0,'zip']\n",
    "len(df_users)\n",
    "for i in range(0, len(df_users)):\n",
    "    if i not in df_users.index:\n",
    "        continue \n",
    "    if (df_users.loc[i, 'zip'] <= 20000):\n",
    "        df_users.loc[i,'zip'] = 0\n",
    "    else:\n",
    "        df_users.loc[i, 'zip'] = str(int(str(df_users.loc[i,'zip'])))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41418421acf012d890729e638c633ce8",
     "grade": true,
     "grade_id": "2g-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users) == 943\n",
    "assert df_users.loc[671, 'zip'] == '285'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d408e9c7e2ebcc5e32d876378bff4110",
     "grade": false,
     "grade_id": "cell-6bd3aeedfe21d1bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3g) Save out the properly anonymized data to json file \n",
    "\n",
    "Save out `df_users` as a json file, called `real_anon_user_dat.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3593036af4db67b62cf68cebbe2994",
     "grade": false,
     "grade_id": "2h",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "df_users.to_json(\"real_anon_user_dat.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a9e25d2ceb20d07c0d08e0c38831860",
     "grade": true,
     "grade_id": "2h-tests",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pd.read_json('real_anon_user_dat.json'), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f5f079ec0fc0fda0bdcb4d12cbbeb8d",
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Complete!\n",
    "\n",
    "Congrats, you're done! The users' identities are much more protected now.\n",
    "\n",
    "Have a look back over your answers, and also make sure to `Restart & Run All` from the kernel menu to double check that everything is working properly. You can also use the 'Validate' button above, which runs your notebook from top to bottom and checks to ensure all `assert` statements pass silently. When you are ready, submit on datahub!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
